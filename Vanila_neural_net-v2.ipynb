{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import tensorflow as tf \n",
    "import zipfile\n",
    "from keras.layers import Dense, Reshape\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from keras.losses import *\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Reshape\n",
    "from keras.layers import LSTM, Flatten, Input, Embedding, concatenate, Concatenate, average, maximum, Dropout\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras import optimizers\n",
    "from keras import backend as K\n",
    "from keras.callbacks import TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def balanceFraudDataframe(df, p): #p is desired fraud/non-fraud ratio\n",
    "    dfFraud = df.loc[df['isFraud']==1,:]\n",
    "    x = len(dfFraud)\n",
    "    n = len(df)\n",
    "    numOfTimesToResample = int((p * n - x)/((1-p) * x))\n",
    "    #print(numOfTimesToResample)\n",
    "    dfBalanced = df\n",
    "    for _ in range(numOfTimesToResample):\n",
    "        dfBalanced = dfBalanced.append(dfFraud)   \n",
    "    return dfBalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPercentFraud(df):\n",
    "    return len(df.loc[df.isFraud == 0, :])/len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(\"data/dataframe_train_v09.pd\")\n",
    "df_fraud = pd.read_pickle('dfFraud.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['isFraud'] = df_fraud['isFraud']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsNotToScale = list(df.columns[(df.dtypes == 'bool') | (df.dtypes=='uint8')])\n",
    "#columnsNotToScale.append('isFraud')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(590540, 402)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop(columnsNotToScale, axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MinMaxScaler(copy=True, feature_range=(0, 1))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "#scaler = StandardScaler()\n",
    "scaler.fit(df.drop('isFraud', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1234)\n",
    "choose = np.random.rand(len(df))\n",
    "dfTrain = df.loc[choose >= .2, :]\n",
    "dfTest = df.loc[choose < .2, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(472515, 750)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert len(dfTrain) + len(dfTest) == len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.964932330190576\n",
      "0.964932330190576\n"
     ]
    }
   ],
   "source": [
    "print(findPercentFraud(dfTrain))\n",
    "dfTrain = balanceFraudDataframe(dfTrain, 0)\n",
    "print(findPercentFraud(dfTrain))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9653209065875874\n"
     ]
    }
   ],
   "source": [
    "print(findPercentFraud(dfTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array(scaler.transform(dfTrain.drop('isFraud', axis=1)))\n",
    "y_train= np.array(dfTrain['isFraud'])\n",
    "#x_test = scaler.transform(dfTest.drop([\"isFraud\"], axis=1))\n",
    "scaler2 = MinMaxScaler(feature_range=(0, 1))\n",
    "scaler2.fit(dfTest.drop('isFraud', axis=1))\n",
    "\n",
    "x_test = np.array(scaler2.transform(dfTest.drop('isFraud', axis=1)))\n",
    "y_test = np.array(dfTest['isFraud'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_train = x_train.astype('float32')\n",
    "#x_test = x_test.astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      " - 21s - loss: 0.1201 - acc: 0.9673 - recall_m: 0.1449 - precision_m: 0.6542 - f1_m: 0.2260\n",
      "Epoch 2/50\n",
      " - 19s - loss: 0.1073 - acc: 0.9712 - recall_m: 0.2392 - precision_m: 0.8195 - f1_m: 0.3624\n",
      "Epoch 3/50\n",
      " - 19s - loss: 0.1042 - acc: 0.9722 - recall_m: 0.2707 - precision_m: 0.8222 - f1_m: 0.3992\n",
      "Epoch 4/50\n",
      " - 19s - loss: 0.1023 - acc: 0.9727 - recall_m: 0.2860 - precision_m: 0.8229 - f1_m: 0.4158\n",
      "Epoch 5/50\n",
      " - 19s - loss: 0.1002 - acc: 0.9731 - recall_m: 0.2989 - precision_m: 0.8261 - f1_m: 0.4302\n",
      "Epoch 6/50\n",
      " - 19s - loss: 0.0988 - acc: 0.9736 - recall_m: 0.3144 - precision_m: 0.8299 - f1_m: 0.4480\n",
      "Epoch 7/50\n",
      " - 19s - loss: 0.0977 - acc: 0.9740 - recall_m: 0.3230 - precision_m: 0.8479 - f1_m: 0.4592\n",
      "Epoch 8/50\n",
      " - 19s - loss: 0.0967 - acc: 0.9741 - recall_m: 0.3280 - precision_m: 0.8510 - f1_m: 0.4650\n",
      "Epoch 9/50\n",
      " - 19s - loss: 0.0952 - acc: 0.9745 - recall_m: 0.3408 - precision_m: 0.8420 - f1_m: 0.4780\n",
      "Epoch 10/50\n",
      " - 19s - loss: 0.0946 - acc: 0.9746 - recall_m: 0.3419 - precision_m: 0.8525 - f1_m: 0.4802\n",
      "Epoch 11/50\n",
      " - 19s - loss: 0.0931 - acc: 0.9749 - recall_m: 0.3486 - precision_m: 0.8518 - f1_m: 0.4871\n",
      "Epoch 12/50\n",
      " - 19s - loss: 0.0920 - acc: 0.9753 - recall_m: 0.3501 - precision_m: 0.8691 - f1_m: 0.4915\n",
      "Epoch 13/50\n",
      " - 19s - loss: 0.0912 - acc: 0.9757 - recall_m: 0.3615 - precision_m: 0.8712 - f1_m: 0.5040\n",
      "Epoch 14/50\n",
      " - 19s - loss: 0.0903 - acc: 0.9758 - recall_m: 0.3675 - precision_m: 0.8729 - f1_m: 0.5096\n",
      "Epoch 15/50\n",
      " - 19s - loss: 0.0896 - acc: 0.9760 - recall_m: 0.3761 - precision_m: 0.8662 - f1_m: 0.5176\n",
      "Epoch 16/50\n",
      " - 19s - loss: 0.0884 - acc: 0.9763 - recall_m: 0.3863 - precision_m: 0.8645 - f1_m: 0.5273\n",
      "Epoch 17/50\n",
      " - 19s - loss: 0.0879 - acc: 0.9762 - recall_m: 0.3871 - precision_m: 0.8678 - f1_m: 0.5274\n",
      "Epoch 18/50\n",
      " - 19s - loss: 0.0867 - acc: 0.9766 - recall_m: 0.3960 - precision_m: 0.8677 - f1_m: 0.5375\n",
      "Epoch 19/50\n",
      " - 19s - loss: 0.0861 - acc: 0.9769 - recall_m: 0.3996 - precision_m: 0.8791 - f1_m: 0.5415\n",
      "Epoch 20/50\n",
      " - 19s - loss: 0.0851 - acc: 0.9772 - recall_m: 0.4122 - precision_m: 0.8707 - f1_m: 0.5527\n",
      "Epoch 21/50\n",
      " - 19s - loss: 0.0839 - acc: 0.9774 - recall_m: 0.4196 - precision_m: 0.8723 - f1_m: 0.5605\n",
      "Epoch 22/50\n",
      " - 19s - loss: 0.0833 - acc: 0.9775 - recall_m: 0.4222 - precision_m: 0.8737 - f1_m: 0.5629\n",
      "Epoch 23/50\n",
      " - 19s - loss: 0.0821 - acc: 0.9778 - recall_m: 0.4283 - precision_m: 0.8832 - f1_m: 0.5705\n",
      "Epoch 24/50\n",
      " - 19s - loss: 0.0818 - acc: 0.9779 - recall_m: 0.4280 - precision_m: 0.8849 - f1_m: 0.5704\n",
      "Epoch 25/50\n",
      " - 19s - loss: 0.0804 - acc: 0.9784 - recall_m: 0.4442 - precision_m: 0.8834 - f1_m: 0.5851\n",
      "Epoch 26/50\n",
      " - 19s - loss: 0.0797 - acc: 0.9785 - recall_m: 0.4472 - precision_m: 0.8820 - f1_m: 0.5870\n",
      "Epoch 27/50\n",
      " - 19s - loss: 0.0791 - acc: 0.9786 - recall_m: 0.4525 - precision_m: 0.8802 - f1_m: 0.5924\n",
      "Epoch 28/50\n",
      " - 19s - loss: 0.0785 - acc: 0.9788 - recall_m: 0.4583 - precision_m: 0.8866 - f1_m: 0.5976\n",
      "Epoch 29/50\n",
      " - 19s - loss: 0.0771 - acc: 0.9792 - recall_m: 0.4685 - precision_m: 0.8865 - f1_m: 0.6074\n",
      "Epoch 30/50\n",
      " - 19s - loss: 0.0762 - acc: 0.9794 - recall_m: 0.4761 - precision_m: 0.8840 - f1_m: 0.6128\n",
      "Epoch 31/50\n",
      " - 19s - loss: 0.0756 - acc: 0.9795 - recall_m: 0.4784 - precision_m: 0.8867 - f1_m: 0.6160\n",
      "Epoch 32/50\n",
      " - 19s - loss: 0.0743 - acc: 0.9799 - recall_m: 0.4842 - precision_m: 0.8958 - f1_m: 0.6232\n",
      "Epoch 33/50\n",
      " - 19s - loss: 0.0735 - acc: 0.9800 - recall_m: 0.4881 - precision_m: 0.8963 - f1_m: 0.6272\n",
      "Epoch 34/50\n",
      " - 19s - loss: 0.0728 - acc: 0.9803 - recall_m: 0.4962 - precision_m: 0.8985 - f1_m: 0.6335\n",
      "Epoch 35/50\n",
      " - 19s - loss: 0.0717 - acc: 0.9805 - recall_m: 0.5024 - precision_m: 0.9014 - f1_m: 0.6397\n",
      "Epoch 36/50\n",
      " - 19s - loss: 0.0709 - acc: 0.9808 - recall_m: 0.5147 - precision_m: 0.8945 - f1_m: 0.6480\n",
      "Epoch 37/50\n",
      " - 19s - loss: 0.0702 - acc: 0.9808 - recall_m: 0.5087 - precision_m: 0.9041 - f1_m: 0.6462\n",
      "Epoch 38/50\n",
      " - 19s - loss: 0.0687 - acc: 0.9813 - recall_m: 0.5226 - precision_m: 0.9054 - f1_m: 0.6577\n",
      "Epoch 39/50\n",
      " - 19s - loss: 0.0683 - acc: 0.9815 - recall_m: 0.5276 - precision_m: 0.9075 - f1_m: 0.6631\n",
      "Epoch 40/50\n",
      " - 19s - loss: 0.0669 - acc: 0.9818 - recall_m: 0.5368 - precision_m: 0.9058 - f1_m: 0.6688\n",
      "Epoch 41/50\n",
      " - 19s - loss: 0.0664 - acc: 0.9819 - recall_m: 0.5438 - precision_m: 0.9013 - f1_m: 0.6730\n",
      "Epoch 42/50\n",
      " - 19s - loss: 0.0655 - acc: 0.9822 - recall_m: 0.5504 - precision_m: 0.9061 - f1_m: 0.6796\n",
      "Epoch 43/50\n",
      " - 19s - loss: 0.0650 - acc: 0.9822 - recall_m: 0.5538 - precision_m: 0.9046 - f1_m: 0.6827\n",
      "Epoch 44/50\n",
      " - 19s - loss: 0.0642 - acc: 0.9825 - recall_m: 0.5592 - precision_m: 0.9074 - f1_m: 0.6870\n",
      "Epoch 45/50\n",
      " - 19s - loss: 0.0631 - acc: 0.9827 - recall_m: 0.5659 - precision_m: 0.9057 - f1_m: 0.6923\n",
      "Epoch 46/50\n",
      " - 19s - loss: 0.0626 - acc: 0.9829 - recall_m: 0.5718 - precision_m: 0.9063 - f1_m: 0.6964\n",
      "Epoch 47/50\n",
      " - 19s - loss: 0.0611 - acc: 0.9832 - recall_m: 0.5799 - precision_m: 0.9097 - f1_m: 0.7039\n",
      "Epoch 48/50\n",
      " - 19s - loss: 0.0606 - acc: 0.9834 - recall_m: 0.5837 - precision_m: 0.9138 - f1_m: 0.7081\n",
      "Epoch 49/50\n",
      " - 19s - loss: 0.0603 - acc: 0.9835 - recall_m: 0.5861 - precision_m: 0.9144 - f1_m: 0.7093\n",
      "Epoch 50/50\n",
      " - 19s - loss: 0.0590 - acc: 0.9838 - recall_m: 0.5967 - precision_m: 0.9127 - f1_m: 0.7174\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f876ce255c0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import class_weight\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from keras import backend as K\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(y_true))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(y_pred))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n",
    "\n",
    "inputs = Input(shape=(749,))\n",
    "# We stack a deep densely-connected network on top\n",
    "x = Dense(600, activation='relu', use_bias=True)(inputs)\n",
    "x = Dense(600,  activation='relu', use_bias=True)(x)\n",
    "#x = Dropout(.2)(x)\n",
    "x = Dense(600, activation='relu', use_bias=True)(x)\n",
    "#x = Dropout(.1)(x)\n",
    "x = Dense(600, activation='relu', use_bias=True)(x)\n",
    "#x = Dropout(.2)(x)\n",
    "x = Dense(400, activation='relu', use_bias=True)(x)\n",
    "x = Dense(200, activation='relu', use_bias=True)(x)\n",
    "# And finally we add the main logistic regression layer\n",
    "output = Dense(1 , activation= \"sigmoid\", name='ANN_output')(x)\n",
    "\n",
    "adam = optimizers.Adam(lr=0.001)\n",
    "model = Model(inputs=inputs, outputs = output)\n",
    "\n",
    "def mean_pred(y_true, y_pred):\n",
    "    return tf.nn.weighted_cross_entropy_with_logits( y_true, logits=y_pred, pos_weight=.0050)\n",
    "\n",
    "\n",
    "# def metrics_cust(y_true, y_pred):\n",
    "#     return tf.metrics.recall(y_true, y_pred)\n",
    "\n",
    "#weights = class_weight.compute_class_weight('balanced',\n",
    "#                                            np.unique(y_train),\n",
    "#                                            y_train)\n",
    "# weights = [4, 1]\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "model.compile(loss=\"binary_crossentropy\", optimizer=adam, metrics=['accuracy', recall_m, precision_m, f1_m])\n",
    "model.fit(x_train, y_train, epochs=50, batch_size=1024, verbose=2, )#class_weight= weights)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 21s - loss: 0.0674 - acc: 0.9814 - recall_m: 0.5384 - precision_m: 0.8881 - f1_m: 0.6604\n",
      "Epoch 2/20\n",
      " - 20s - loss: 0.0653 - acc: 0.9820 - recall_m: 0.5505 - precision_m: 0.8985 - f1_m: 0.6727\n",
      "Epoch 3/20\n",
      " - 20s - loss: 0.0639 - acc: 0.9824 - recall_m: 0.5627 - precision_m: 0.9001 - f1_m: 0.6833\n",
      "Epoch 4/20\n",
      " - 20s - loss: 0.0627 - acc: 0.9827 - recall_m: 0.5697 - precision_m: 0.9036 - f1_m: 0.6899\n",
      "Epoch 5/20\n",
      " - 21s - loss: 0.0619 - acc: 0.9829 - recall_m: 0.5815 - precision_m: 0.8970 - f1_m: 0.6963\n",
      "Epoch 6/20\n",
      " - 20s - loss: 0.0609 - acc: 0.9831 - recall_m: 0.5823 - precision_m: 0.9042 - f1_m: 0.6995\n",
      "Epoch 7/20\n",
      " - 20s - loss: 0.0606 - acc: 0.9832 - recall_m: 0.5846 - precision_m: 0.9045 - f1_m: 0.7020\n",
      "Epoch 8/20\n",
      " - 20s - loss: 0.0595 - acc: 0.9835 - recall_m: 0.5955 - precision_m: 0.9029 - f1_m: 0.7078\n",
      "Epoch 9/20\n",
      " - 20s - loss: 0.0601 - acc: 0.9835 - recall_m: 0.5952 - precision_m: 0.9064 - f1_m: 0.7095\n",
      "Epoch 10/20\n",
      " - 20s - loss: 0.0579 - acc: 0.9839 - recall_m: 0.6056 - precision_m: 0.9070 - f1_m: 0.7174\n",
      "Epoch 11/20\n",
      " - 20s - loss: 0.0577 - acc: 0.9840 - recall_m: 0.6082 - precision_m: 0.9049 - f1_m: 0.7197\n",
      "Epoch 12/20\n",
      " - 20s - loss: 0.0568 - acc: 0.9841 - recall_m: 0.6130 - precision_m: 0.9083 - f1_m: 0.7226\n",
      "Epoch 13/20\n",
      " - 20s - loss: 0.0563 - acc: 0.9845 - recall_m: 0.6196 - precision_m: 0.9108 - f1_m: 0.7291\n",
      "Epoch 14/20\n",
      " - 21s - loss: 0.0551 - acc: 0.9847 - recall_m: 0.6270 - precision_m: 0.9101 - f1_m: 0.7341\n",
      "Epoch 15/20\n",
      " - 21s - loss: 0.0540 - acc: 0.9849 - recall_m: 0.6359 - precision_m: 0.9102 - f1_m: 0.7403\n",
      "Epoch 16/20\n",
      " - 21s - loss: 0.0679 - acc: 0.9817 - recall_m: 0.5367 - precision_m: 0.9061 - f1_m: 0.6603\n",
      "Epoch 17/20\n",
      " - 21s - loss: 0.0540 - acc: 0.9849 - recall_m: 0.6339 - precision_m: 0.9125 - f1_m: 0.7403\n",
      "Epoch 18/20\n",
      " - 21s - loss: 0.0603 - acc: 0.9835 - recall_m: 0.5860 - precision_m: 0.9147 - f1_m: 0.7015\n",
      "Epoch 19/20\n",
      " - 21s - loss: 0.0526 - acc: 0.9855 - recall_m: 0.6480 - precision_m: 0.9138 - f1_m: 0.7502\n",
      "Epoch 20/20\n",
      " - 21s - loss: 0.0516 - acc: 0.9856 - recall_m: 0.6514 - precision_m: 0.9142 - f1_m: 0.7536\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f8bc45ee8d0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=500, verbose=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      " - 19s - loss: 0.0409 - acc: 0.9888 - recall_m: 0.7152 - precision_m: 0.9542 - f1_m: 0.8169\n",
      "Epoch 2/20\n",
      " - 19s - loss: 0.0367 - acc: 0.9901 - recall_m: 0.7504 - precision_m: 0.9578 - f1_m: 0.8411\n",
      "Epoch 3/20\n",
      " - 19s - loss: 0.0353 - acc: 0.9905 - recall_m: 0.7640 - precision_m: 0.9577 - f1_m: 0.8495\n",
      "Epoch 4/20\n",
      " - 19s - loss: 0.0340 - acc: 0.9909 - recall_m: 0.7730 - precision_m: 0.9608 - f1_m: 0.8564\n",
      "Epoch 5/20\n",
      " - 19s - loss: 0.0332 - acc: 0.9912 - recall_m: 0.7794 - precision_m: 0.9615 - f1_m: 0.8605\n",
      "Epoch 6/20\n",
      " - 19s - loss: 0.0327 - acc: 0.9914 - recall_m: 0.7830 - precision_m: 0.9645 - f1_m: 0.8638\n",
      "Epoch 7/20\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train, epochs=20, batch_size=5000, verbose=2, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y_test, model.predict(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model_sub2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subm = pd.read_pickle('./data/dataframe_test_v09.pd')\n",
    "x_sub = scaler.transform(df_subm)\n",
    "y_pred = model.predict(x_sub)\n",
    "dfToSubmit = pd.DataFrame(y_pred)\n",
    "dfToSubmit.columns = ['isFraud']\n",
    "dfToSubmit.index = df_subm.index\n",
    "dfToSubmit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfToSubmit.to_csv('./final_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainPredict = model.predict(x_train)\n",
    "testPredict = model.predict(x_test)\n",
    "# calculate root mean squared error\n",
    "trainScore = math.sqrt(mean_squared_error(y_train, trainPredict))\n",
    "#trainScore = numpy.mean(numpy.abs((y_train - trainPredict))/y_train)\n",
    "\n",
    "print('Train Score: %.2f MAPE' % (trainScore))\n",
    "testScore = math.sqrt(mean_squared_error(y_test, testPredict))\n",
    "#testScore =  numpy.mean(numpy.abs((y_test - testPredict))/y_test)\n",
    "\n",
    "print('Test Score: %.2f MAPE' % (testScore))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import TomekLinks\n",
    "sampler = TomekLinks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "l = df.shape[0]//n\n",
    "X_ress = []\n",
    "y_ress = []\n",
    "for i in range(n):\n",
    "    print(i)\n",
    "    X_res, y_res = sampler.fit_resample(df[i*l:(i+1)*l], df_fraud[i*l:(i+1)*l].values.reshape(-1))\n",
    "    X_ress.append(X_res)\n",
    "    y_ress.append(y_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res = np.vstack(X_ress)\n",
    "y_res = np.hstack(y_ress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res, y_res = sampler.fit_resample(df, df_fraud.values.reshape(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_res.shape[0]/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./data/dataframe_train_v07.np', 'wb') as f:\n",
    "    pickle.dump(X_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./dfFraud.np', 'wb') as f:\n",
    "    pickle.dump(y_res, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud_res = pd.DataFrame(y_res, X_res[:,0].astype('int32'), df_fraud.columns)#, [str(i) for i in df_fraud.dtypes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame?\n",
    "#(X_res, X_res[:,0].astype('int32'), df.columns, dtype="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in df.columns:\n",
    "    df_res[column] = df_res[column].astype(df[column].dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res.to_pickle('data/dataframe_train_v07.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fraud_res.to_pickle('./dfFraud_v07.pd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
